---
title: "Semana 21: Nubes de puntos controladas y mapa campamento"
excerpt_separator: "<!--more-->"
categories:
  - Blog
tags:
  - CARLA
  - Unreal
  - PythonAPI
  - LiDAR
  - Submuestreo
---

## Objetivo
Se pretende tener soltura a la hora de usar el sensor LiDAR de CARLA para la creación de datasets que cumplan con las especificaciones necesarias en dicho momento.

## Parámetros Clave del LiDAR Semántico
Primero hay que volver a tener en cuenta todos los parámetros base del sensor:


| Parámetro            | Descripción                                | Valores Recomendados       |
|----------------------|--------------------------------------------|----------------------------|
| `channels`          | Número de haces láser (densidad vertical)   | 16 (baja), 32 (media), 64 (alta)|
| `points_per_second` | Cantidad de puntos generados por segundo    | 100,000 - 1,000,000|
| `range`             | Alcance máximo del sensor (metros)           | 20 - 100 m                  |
| `rotation_frequency`| Veces que el sensor rota por segundo        | 10 - 30 Hz                  |
| `upper_fov`         | Ángulo superior del campo de visión         | 10° a 30°                  |
| `lower_fov`         | Ángulo inferior del campo de visión	        | -10° a -30°                |
| `horizontal_fov`    | Ángulo horizontal de escaneo                | 180° o 360°                |


Pero también hay que tener en cuenta los parámetros añadidos las anteriores semanas para simular un escenario más realista:

| Parámetro            | Descripción                                | Valores Recomendados       |
|----------------------|--------------------------------------------|----------------------------|
| `drop_rate`          | Probabilidad de que un punto LiDAR no sea registrado     | 0.45|
| `intensity_limit`    | Umbral de intensidad con el que los puntos son protegidos| 0.8 |
| `zero_intensity_drop`| Factor adicional de eliminación para puntos con intensidad baja| 0.4|
| `low_intensity_threshold`| Umbral de intensidad de los puntos que se consideran bajos| 0.01|
| `noise_std`         | Ruido Gaussiano añadido         | 0.1 (desviación estándar del ruido Gaussiano aplicado a los puntos)|
| `voxel_size`         | amaño del voxel usado en el proceso de submuestreo, afectando la resolución de la nube de puntos| 0.5 m|


## points_per_second vs Puntos por frame
El párametro principal que se tiene en cuenta para la densidad de las nubes de puntos es **points_per_second**. Sin embargo, es importante entender que este valor se distribuye equitativamente entre todas las nubes de puntos generadas en cada segundo. Por lo tanto, para ajustar la densidad real de los puntos por fotograma, es fundamental controlar la cantidad de frames generados por segundo. Esto se puede hacer ajustando el parámetro fixed_delta_seconds en la configuración del mundo cuando se usa el modo síncrono, donde **FPS** se obtiene como **1/fixed_delta_seconds** en modo síncrono.
Es importante no confundir los FPS del simulador con los FPS que se ven en pantalla.
- FPS del simulador: Dependen del valor de fixed_delta_seconds. En modo síncrono, el simulador controla cuántos pasos (frames) se generan por segundo, lo que afecta directamente a la densidad de la nube de puntos.

- FPS en pantalla: Dependen del rendimiento de la GPU y la tasa de refresco del monitor. Un simulador puede generar 10 FPS, pero la pantalla puede estar refrescando a 60 Hz.

Se han realizado diversas pruebas con la `delta` y `points_per_second`, utilizando como base los siguientes parámetros del sensor:
- channels: 64
- range: 100
- rotation_frequency: 10
- upper_fov: 30
- lower_fov: -45
- horizontal_fov: 360

Pruebas realizadas:

| delta  | FPS  | points/sec | Pts/frame (ideal) | Pts/frame (drop) | Pts/frame (voxel) |
|--------|------|------------|-------------------|------------------|-------------------|
| 0.025s | 40   | 1000000    | 25 000            | 15 000           | 5 500             |
| 0.05s  | 20   | 1000000    | 45 000            | 28 000           | 9 500             |
| 0.1s   | 10   | 1000000    | 80 000            | 55 000           | 11 000            |
| 0.2s   | 5    | 1000000    | 155 000           | 105 000          | 16 500            |
| 0.3s   | ~3.3 | 1000000    | 275 000           | 180 000          | 23 500            |
| 0.025s| 40    | 500000     | 12 000            | 8 000            | 2 000             |
| 0.05s | 20    | 500000     | 22 500            | 15 000           | 4 500             |
| 0.1s  | 10    | 500000     | 45 000            | 30 000           | 9 000             |
| 0.2s  | 5     | 500000     | 90 000            | 59 000           | 15 000            |
| 0.3s  | ~3.3  | 500000     | 130 000           | 87 000           | 15 000            |
| 0.025s| 40    | 100000     | 2 500             | 1 500            | 800               |
| 0.05s | 20    | 100000     | 4 500             | 3 000            | 1 500             |
| 0.1s  | 10    | 100000     | 9 200             | 6 000            | 3 000             |
| 0.2s  | 5     | 100000     | 17 000            | 11 000           | 4 500             |
| 0.3s  | ~3.3  | 100000     | 26 000            | 17 000           | 6 500    

> ⚠️ **Nota**: Los valores pueden variar ligeramente entre frames, debido a:
> - Diferente número de objetos por frame (afecta `Pts/frame`)
> - Variación en las pérdidas (más puntos no registrados)
> - Filtrado por intensidad (mayor número de puntos por debajo del umbral)


## Análisis detallado de los parámetros y sus usos
Se han realizado diversas pruebas con cada parámetro del sensor para analizar sus usos sin usar el submuestreo por vóxeles, utilizando como base los siguientes parámetros del sensor:
- channels: 64
- range: 100
- rotation_frequency: 30
- upper_fov: 30
- lower_fov: -30
- horizontal_fov: 360
- points_per_second: 500.000
- delta: 0.0025
- drop_rate: 0.45
- intensity_limit: 0.8
- zero_intensity_drop: 0.4
- low_intensity_threshold: 0.01
- noise_std: 0.1

### `horizontal_fov`
Determina el ángulo total en el plano horizontal que el LiDAR cubre durante cada rotación. En caminos sin asfaltar, normalmente se desea prestar atención principal a lo que hay delante del vehículo, ya que las rutas son más irregulares y estrechas. Un campo de visión amplio puede generar datos irrelevantes como árboles o vegetación lateral, mientras que uno acotado mejora el enfoque en el camino.

Recomendaciones de uso:

- 90°–120°: Ideal para escaneo únicamente frontal. Se consiguen datos más enfocados y con menor ruido lateral, útil en senderos angostos o en tareas de detección de obstáculos frontales. Al concentrar los puntos en una menor zona, se logra un mejor nivel de detalle utilizando una menor cantidad de puntos. Sin embargo, existe el riesgo de no captar elementos importantes en curvas cerradas.

<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Horizontal_fov_90.png" alt="Ejemplo con 90º">
</figure>

- 180°: Proporciona una vista semicompleta del entorno, útil en caminos rurales donde puede ser necesario observar también los laterales. Se consigue un buen balance entre foco frontal y contexto lateral que puede ser útil a pesar del aumento de puntos a procesar.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Horizontal_fov_180.png" alt="Ejemplo con 180º">
</figure>

- 360°: Recomendado solo en situaciones donde es imprescindible analizar el entorno colmpleto. Con esta configuración se consigue la información total del entorno, pero puede aumentar innecesariamente el tamaño del dataset con puntos irrelevantes para el contexto específico.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Horizontal_fov_360.png" alt="Ejemplo con 360º">
</figure>

### `channels`
Este parámetro se refiere al número de planos de escaneo en el eje vertical. Aumentar el número de canales mejora la resolución vertical de la nube de puntos, lo que significa que se generarán más puntos a diferentes alturas en un área determinada. Esto es útil cuando se necesita un detalle vertical mayor, como en el caso de terrenos irregulares.

Recomendaciones de uso:

- 16 canales: Suficiente para caminos de tierra donde las variaciones en altura no son tan extremas y la prioridad es el rendimiento. Esto es útil para simulaciones en las que el detalle vertical no es tan crítico.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Canales_16.png" alt="Ejemplo con 16 canales">
</figure>

- 32 canales: Una opción equilibrada para caminos de tierra, donde es necesario captar más detalles del terreno y las elevaciones del camino sin generar un dataset excesivamente grande.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Canales_32.png" alt="Ejemplo con 32 canales">
</figure>

- 64 canales: Recomendado si el terreno es muy accidentado y se necesita capturar una gran cantidad de detalles verticales.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Canales_64.png" alt="Ejemplo con 64 canales">
</figure>


### `range`
El rango determina hasta qué distancia el LiDAR puede detectar objetos. Un mayor alcance permite capturar detalles de objetos lejanos, pero también puede generar nubes de puntos más dispersas. Para caminos irregulares, el alcance adecuado es crucial para detectar obstáculos a tiempo y ajustar la velocidad del vehículo.

- 25 metros: Ideal para caminos estrechos donde los objetos se encuentran principalmente cerca. Ayuda a controlar el tamaño del dataset y la precisión en la detección de obstáculos cercanos. Se consigue un mejor detalle de los objetos cercanos al emplear todos los puntos del frame en un área menor, también pueden usarse un menor número de canales. Hay que controlas los puntos por segundo puesto, ya que si se pone ún numero elevado, no se llegan a usar al ser un espacio mucho más pequeño. En este ejemplo, se han reducido unos 5000 puntos en comparación con rangos más amplios.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Metros-25.png" alt="Ejemplo con 25 metros">
</figure>

- 50 metros: Útil para detectar objetos más alejados del vehículo sin perder mucha precisión por usarse los puntos en un espacio más amplio y sin espaciarse demasiado los canales.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Metros-50.png" alt="Ejemplo con 50 metros">
</figure>

- 100 metros: Puede ser útil en escenarios más abiertos, pero podría generar una nube de puntos menos precisa y con posibilidad de usar más canales para no perder demasiada precisión en objetos cercanos.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Metros-100.png" alt="Ejemplo con 100 metros">
</figure>


### `upper_fov` y `lower_fov` 
Estos parámetros determinan el rango vertical que cubre el sensor LiDAR. Cuanto mayor sea la diferencia entre estos ángulos, mayor será el campo de visión del LiDAR en el eje vertical.

Recomendaciones de uso:

- Ángulo reducido (15° a –15°): Ideal para caminos planos donde el enfoque es el camino y se necesita más detalle en obstáculos cercanos no muy elvados. Pero en caminos irregulares puede faltar información al no capturar bien las variaciones del terreno o en caso de que se quiera detectar la forma de objetos más grandes en zonas cercanas.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Vertical_fov_15.png" alt="Ejemplo con 15 a -15º">
</figure>

- Ángulo amplio (30° a –30°): Recomendado cuando se quiere captar tanto el entorno del vehículo como detalles de los objetos cercanos en el suelo, útil cuando se busca una visión más completa de los obstáculos cercanos. Detecta mejor las variaciones del terreno al usar un rango más amplio.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Vertical_fov_30.png" alt="Ejemplo con 30 a -30º">
</figure>

- Ángulos muy amplios (45 a -45 o más): Útil si se quiere una visión más completa del etorno o para terrenos muy complejos, pero se pueden llegar a generar muchos puntos irrelevantes que no proporcionan nada de información útil, como copas de los árboles. Si se quieren buenos detalles de los objetos sería necesario un mayor número de canales, ya que se esparcen por todo el rango vertical, y por lo tanto tambien un mayor número de puntos por frame, lo que lo puede volver más caro a pesar de no obtener resultado mucho mejores con respecto a 30º.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Vertical_fov_45.png" alt="Ejemplo con 45 a -45º">
</figure>

### `rotation_frequency`
Este parámetro se refiere a la velocidad a la que el LiDAR rota para escanear el entorno.

Recomendaciones de uso:
- Frecuencia baja (5 Hz - 10 Hz). Se consigue una mayor densidad de puntos por revolución (el LiDAR gira más lento y captura más puntos en un mismo ángulo). Tiene una mayor utilida para entornos estáticos, pero en entornos dinámicos se pueden llegar a perder datos.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Frecuencia_10.png" alt="Ejemplo con 10 Hz">
</figure>

- Frecuencia media (10 Hz - 20 Hz). Se consigue un mejor equilibrio entre densidad y actualización de los datos, ya que permite capturar suficientes detalles sin generar lagunas my grandes entre escaneos. Pero todavía se pueden llegar a perder datos, sobre todo con grandes velocidades.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Frecuencia_20.png" alt="Ejemplo con 30 Hz">
</figure>


- Frecuencia alta (20 Hz - 30 Hz o más). Captura datos más frecuentemente, mejorando la percepción en movimiento. Reduce la densidad por revolución, por lo que es probable que se necesiten una mayor cantidad de puntos por segundo. Pero debido a que captura un ángulo mayor, es más recomendado para entornos dinámicos.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Frecuencia_30.png" alt="Ejemplo con 20 Hz">
</figure>

### `noise_std`
Define la desviación estándar del ruido gaussiano añadido a cada punto de la nube de puntos.

Recomendaciones de uso:
- Bajo (noise_std≤ 0.05). La nube de puntos sigue la forma original con poca distorsión, lo que resulta útil para entornos donde se necesita precisión, aunque se pierde realismo en la simulación.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Ruido_0,05.png" alt="Ejemplo con 0,05 de ruido">
</figure>

- Moderado (0.05 ≤ noise_std ≤ 0.2). Puede ser útil para simulaciones más realistas, imitando sensores reales.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Ruido_0,05.png" alt="Ejemplo con 0,1 de ruido">
</figure>

- Alto (noise_std > 0.2). La nube de puntos se vuelve más dispersa y menos precisa, se puede usar para sumular sensores con ruidos mucho más elevados.
<figure class="align-center" style="max-width: 100%">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/Semana-21-Ruido_0,05.png" alt="Ejemplo con 0,2 de ruido">
</figure>

## Nuevo mapa
Para la creación de un nuevo mapa simulando una zona de campamento se ha necesitado buscar nuevos modelos a traves de [Sketchfab](https://sketchfab.com/Rainmender/collections/campamento-ee1822d5770d4dfe87e2a1c01722a8ec)

<iframe width="560" height="315" src="https://www.youtube.com/embed/M7LXrWwrkSg?si=baKTPzLl4Zk42KxO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### [Dataset](https://drive.google.com/file/d/1ZDM98M1J_XTeab62xgp97SY103W7EddK/view?usp=sharing)
